# CEval评估

## 使用场景

### 问题描述

`CEval` 是由中国高校和科研机构联合构建的中文多学科评估数据集，具有以下核心特征：

- **数据规模**：包含 13,468 道涵盖52个学科的四选一客观题

- **学术权威性**：题目均来自中国高等教育考试及专业资格认证，具有学科代表性

- **知识深度**：需结合学科知识体系和逻辑推理能力进行解答

- **学科分布**：覆盖人文科学、社会科学、STEM（科学/技术/工程/数学）和交叉学科四大门类


MindSpeed-LLM 会对`val`题目集中的内容进行评估。

## 使用方法

### 1. 直接评估模式（默认）

#### 使用影响

此模式将会读取对外的`ceval`评估的[模板的文件](../../../../../mindspeed_llm/tasks/evaluation/eval_impl/fewshot_template/ceval_5shot_template.json)作为评估模板，在与需要模型回答的问题连接后，输入到模型中，直接进行评估。

此种模式下，模型的第一个输出将会作为答案。

该模式的优势是直接且速度快，可以直接对模型的预训练权重进行评估。

#### 推荐参数配置

【--max-new-tokens】  

设置为2（确保生成单个选项字符）

### 2. 微调模板评估模式

#### 使用影响

此模式将会读取您的启动脚本中的`DATA_PATH`路径中的同级`dev`文件夹中对应问题的以dev_csv结尾的文件，作为模板问题，经处理后输入到模型中。

与直接评估模式不同的是，该模式会根据种子数，打乱dev文件中的模板问题的顺序。再与需要模型回答的问题连接后，再进行对话模板处理后，将得到的对话字典输入到模型中进行评估。

该模式的优势是评估速度较快，适用于对模型的微调权重进行评估。

### 推荐参数配置

【--max-new-tokens】

设置为2（确保生成单个选项字符）

【--prompt-type】

设置--prompt-type为您在使用MindSpeed-LLM进行微调时的使用的prompt-type名称。

### 3. 平替模板输出模式

#### 使用影响

与`微调模板评估模式`相同的是，该模式也会使用您评估脚本中的`DATA_PATH`路径中`dev`文件夹中对应问题的以dev_csv的文件，并作为模板问题。

与其他模型不同的是，该模式不会打乱模板问题的顺序。模板问题与需要模型回答的问题连接后，不进行对话字典的处理，并输入到模型中，得到前向输出。

该模式的优势是可以使用与业界优秀评估方案相同的评估模板进行评估，并获得较好的评估分数。

### 推荐参数配置

【--max-new-tokens】

设置为2（确保生成单个选项字符）

【--alternative-prompt】

使能`平替模板输出模式`