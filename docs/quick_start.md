# å¿«é€Ÿå…¥é—¨ï¼šQwen2.5 æ¨¡å‹é¢„è®­ç»ƒ

å½“å‰æ–‡æ¡£æä¾›äº†ä¸€ä¸ªç®€å•ç¤ºä¾‹ï¼Œæ–¹ä¾¿æ–°æ¥è§¦MindSpeed-LLMçš„å¼€å‘è€…ä»¬å¯ä»¥å¿«é€Ÿä¸Šæ‰‹ï¼Œå°†æ¨¡å‹è®­ç»ƒä»»åŠ¡è·‘èµ·æ¥ã€‚ä¸‹é¢ä»¥Qwen2.5-7Bæ¨¡å‹ä¸ºä¾‹ï¼ŒæŒ‡å¯¼å¼€å‘è€…å®ŒæˆQwen2.5-7Bå¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡ï¼Œä¸»è¦åŒ…å«å¦‚ä¸‹æ­¥éª¤ï¼š
- ç¯å¢ƒæ­å»ºï¼šåŸºäºä»“åº“æŒ‡å¯¼æ–‡ä»¶æ­å»ºç¯å¢ƒ
- å¼€æºæ¨¡å‹æƒé‡è·å–ï¼šä»HuggingFaceä¸‹è½½Qwen2.5-7BåŸå§‹æ¨¡å‹
- å¯åŠ¨é¢„è®­ç»ƒï¼šåœ¨æ˜‡è…¾NPUä¸Šè¿›è¡Œæ¨¡å‹é¢„è®­ç»ƒ

å¼€å‘è€…å…¥é—¨åŸºç¡€ï¼š
- å…·å¤‡åŸºç¡€PyTorchä½¿ç”¨ç»éªŒ
- å…·å¤‡åˆç­‰pythonå¼€å‘ç»éªŒ
- å¯¹äºMegatron-LMä»“åº“æœ‰æ¦‚ç•¥çš„äº†è§£

# 1 ç¯å¢ƒæ­å»º

å¦‚æœå·²ç»å®Œæˆäº†ç¯å¢ƒæ­å»ºï¼Œè¯·è·³è½¬2ï¼Œè¿›è¡Œé¢„è®­ç»ƒä»»åŠ¡æ‹‰èµ·ã€‚

è¯·å‚è€ƒMindSpeed-LLMä»“é¦–é¡µ[â€œç‰ˆæœ¬é…å¥—è¡¨â€](../README.md#ç‰ˆæœ¬é…å¥—è¡¨)ï¼Œé€‰æ‹©ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„è½¯ä»¶ä¾èµ–ï¼Œå¦‚ä¸‹ä¸»è¦æä¾›ä¸€äº›å›¾ç¤ºæŒ‡å¯¼è¯´æ˜ï¼Œå®Œæˆç¯å¢ƒæ­å»ºï¼Œæœ¬ç« èŠ‚é€šè¿‡é…å›¾è¾…åŠ©æ‚¨å®Œæˆç¯å¢ƒå®‰è£…ã€‚
> å…·ä½“é…å¥—ç‰ˆæœ¬å…³ç³»ï¼Œä»¥ç‰ˆæœ¬é…å¥—è¡¨ä¸ºå‡†ã€‚

## 1.1 é©±åŠ¨å›ºä»¶å®‰è£…

å‚è€ƒç‰ˆæœ¬é…å¥—è¡¨ï¼Œæ ¹æ®ç³»ç»Ÿå’Œç¡¬ä»¶äº§å“å‹å·ï¼Œé€‰æ‹©å¯¹åº”ç‰ˆæœ¬çš„`driver`å’Œ`firmware`ä¸‹è½½[é©±åŠ¨å›ºä»¶](https://www.hiascend.com/hardware/firmware-drivers/community)ï¼Œå¹¶å‚è€ƒå®Œæˆ[NPUé©±åŠ¨å›ºä»¶å®‰è£…](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/81RC1alpha002/softwareinst/instg/instg_0005.html?Mode=PmIns&OS=Ubuntu&Software=cannToolKit)ï¼Œå®‰è£…åé‡å¯osç³»ç»Ÿç”Ÿæ•ˆã€‚

## 1.2 CANNå®‰è£…

å‚è€ƒç‰ˆæœ¬é…å¥—è¡¨ï¼Œæ ¹æ®ç³»ç»Ÿé€‰æ‹©`aarch64`æˆ–`x86_64`å¯¹åº”ç‰ˆæœ¬çš„`cann-toolkit`ã€`cann-kernel`å’Œ`cann-nnal`ï¼Œä¸‹è½½[CANNè½¯ä»¶åŒ…](https://www.hiascend.com/developer/download/community/result?module=cann)ï¼Œå‚è€ƒ[CANNå®‰è£…æ•™ç¨‹](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/81RC1alpha002/softwareinst/instg/instg_0008.html?Mode=PmIns&OS=Ubuntu&Software=cannToolKit)å®ŒæˆcannåŒ…å®‰è£…ã€‚

## 1.3 ç›¸å…³ä¾èµ–å®‰è£…

**pytorchåç«¯ç›¸å…³ä¾èµ–ç¯å¢ƒä¸mindsporeç¯å¢ƒäº’ç›¸å†²çªï¼Œè¯·æ ¹æ®éœ€è¦ï¼Œæ‹©ä¸€å®‰è£…ã€‚**

### Pytorchåç«¯ç›¸å…³ä¾èµ–å®‰è£…

è¯·å‚è€ƒMindSpeed-LLMä»“é¦–é¡µ[â€œç‰ˆæœ¬é…å¥—è¡¨â€](../README.md#ç‰ˆæœ¬é…å¥—è¡¨)ï¼Œå‡†å¤‡[torch_npu](https://www.hiascend.com/developer/download/community/result?module=pt)å’Œ[apex](https://gitee.com/ascend/apex)ï¼Œå‚è€ƒ[Ascend Extension for PyTorch](https://www.hiascend.com/document/detail/zh/Pytorch/700/configandinstg/instg/insg_0001.html)æˆ–æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…

```shell
# å®‰è£…torchå’Œtorch_npuï¼Œå› ä¸ºç‰ˆæœ¬è¿­ä»£ï¼ŒåŒ…åå­˜åœ¨å‡ºå…¥ï¼Œæ ¹æ®å®é™…ä¿®æ”¹
wget https://download.pytorch.org/whl/cpu/torch-2.1.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl
pip install torch-2.1.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl
wget https://gitee.com/ascend/pytorch/releases/download/v7.0.0-pytorch2.1.0/torch_npu-2.1.0.post12-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl
pip install torch_npu-2.1.0.post12-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl

# apex for Ascend éœ€è¦è‡ªè¡Œå‚è€ƒ https://gitee.com/ascend/apex å®ŒæˆwhlåŒ…çš„æ„å»ºï¼Œå†é€šè¿‡å¦‚ä¸‹æŒ‡ä»¤å®Œæˆå®‰è£…
pip install apex-*.whl
```

æ‹‰å–ä»£ç ä»“å¹¶å®Œæˆå®‰è£…:
```shell
# è®¾ç½®ç¯å¢ƒå˜é‡
source /usr/local/Ascend/ascend-toolkit/set_env.sh
source /usr/local/Ascend/nnal/atb/set_env.sh

# å®‰è£…MindSpeedåŠ é€Ÿåº“
git clone https://gitee.com/ascend/MindSpeed.git
cd MindSpeed
git checkout master              # ä»¥install_guide.mdä¸­çš„ç‰ˆæœ¬ä¸ºå‡†ï¼Œæ­¤å¤„ä»…åšå‚è€ƒ
pip install -r requirements.txt
pip3 install -e .
cd ..

# å‡†å¤‡MindSpeed-LLMåŠMegatron-LMæºç 
git clone https://gitee.com/ascend/MindSpeed-LLM.git
git clone https://github.com/NVIDIA/Megatron-LM.git  # megatronä»githubä¸‹è½½ï¼Œè¯·ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®
cd Megatron-LM
git checkout core_r0.8.0         # ä»¥install_guide.mdä¸­çš„ç‰ˆæœ¬ä¸ºå‡†ï¼Œæ­¤å¤„ä»…åšå‚è€ƒ
cp -r megatron ../MindSpeed-LLM/
cd ../MindSpeed-LLM
git checkout master              # ä»¥install_guide.mdä¸­çš„ç‰ˆæœ¬ä¸ºå‡†ï¼Œæ­¤å¤„ä»…åšå‚è€ƒ

pip install -r requirements.txt  # å®‰è£…å…¶ä½™ä¾èµ–åº“
```

### MindSporeåç«¯åŠç›¸å…³ä¾èµ–å®‰è£…

è¯·å‚è€ƒMindSporeä»“[â€œç‰ˆæœ¬é…å¥—è¡¨â€](mindspore/readme.md#ç‰ˆæœ¬é…å¥—è¡¨)ï¼Œå®‰è£…æŒ‡å®šç‰ˆæœ¬ã€‚

å‚è€ƒ[MindSporeå®˜æ–¹å®‰è£…æŒ‡å¯¼](https://www.mindspore.cn/install)ï¼Œæ ¹æ®ç³»ç»Ÿç±»å‹ã€CANNç‰ˆæœ¬åŠPythonç‰ˆæœ¬é€‰æ‹©åŒ¹é…çš„å¯¹åº”çš„å®‰è£…å‘½ä»¤è¿›è¡Œå®‰è£…ï¼Œå®‰è£…å‰è¯·ç¡®ä¿ç½‘ç»œç•…é€šã€‚æˆ–æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

```shell
pip install mindspore==2.7.0  # ä»¥docs/mindspore/readme.mdä¸­çš„ç‰ˆæœ¬ä¸ºå‡†ï¼Œæ­¤å¤„ä»…åšå‚è€ƒ
```

```shell
# æ‹‰å–MindSpeed-Core-MSä»“åº“
git clone https://gitee.com/ascend/MindSpeed-Core-MS.git -b r0.3.0
cd MindSpeed-Core-MS
pip install requirements.txt
source auto_convert_llm.sh

# å®Œæˆå®‰è£…ï¼Œè¿”å›LLMæ‰§è¡Œæ¨¡å‹ä»»åŠ¡
cd MindSpeed-LLM
```

# 2 å¼€æºæ¨¡å‹æƒé‡è·å–

é€šè¿‡ wget ä»HuggingFaceä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚

```bash
# åˆ›å»ºä¸€ä¸ªç›®å½•å­˜å‚¨huggingfaceæ–‡ä»¶
mkdir -p ./model_from_hf/qwen2.5-7b-hf
cd ./model_from_hf/qwen2.5-7b-hf

# wgetè·å–æƒé‡æ–‡ä»¶
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/config.json
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/generation_config.json
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/merges.txt
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/model-00001-of-00004.safetensors
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/model-00002-of-00004.safetensors
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/model-00003-of-00004.safetensors
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/model-00004-of-00004.safetensors
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/model.safetensors.index.json
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/tokenizer.json
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/tokenizer_config.json
wget https://huggingface.co/Qwen/Qwen2.5-7B/tree/main/vocab.json
```

é€šè¿‡md5suméªŒè¯æ¨¡å‹æƒé‡æ–‡ä»¶å®Œæ•´æ€§
```bash
# åˆ©ç”¨sha256sumè®¡ç®— SHA256æ•°å€¼
# æ‰“å¼€æ–‡ä»¶æ˜ç»†å¯è·å–sha256å€¼ï¼Œhttps://huggingface.co/Qwen/Qwen2.5-7B/blob/main/model-00001-of-00004.safetensors
sha256sum model-00001-of-00004.safetensors
sha256sum model-00002-of-00004.safetensors
sha256sum model-00003-of-00004.safetensors
sha256sum model-00004-of-00004.safetensors
```
![img.png](../sources/images/quick_start/sha256.png)

![img_1.png](../sources/images/quick_start/sha256_hf.png)

# 3 åŸºäºpytorchåç«¯çš„é¢„è®­ç»ƒ

åœ¨è¿™ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬å°†åŸºäºä¸‹è½½çš„HuggingFace(hf)åŸæ•°æ®ï¼Œå®Œæˆæƒé‡è½¬æ¢ã€æ•°æ®é›†é¢„å¤„ç†ï¼Œå¯åŠ¨æ¨¡å‹é¢„è®­ç»ƒï¼ŒåŒ…å«æ­¥éª¤å¦‚ä¸‹ï¼š

- hfæƒé‡è½¬æ¢æˆmegatronæƒé‡ï¼›
- é¢„è®­ç»ƒæ•°æ®é›†å¤„ç†ï¼›
- é¢„è®­ç»ƒä»»åŠ¡å¯åŠ¨ã€‚

## 3.1 æƒé‡è½¬æ¢

æ˜‡è…¾MindSpeed-LLMè¦æ±‚æ¨¡å‹æƒé‡é‡‡ç”¨Megatron-LMæ ¼å¼ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†åŸå§‹HuggingFaceæƒé‡æ ¼å¼è½¬æ¢ä¸ºMegatron-Mcoreæ ¼å¼ã€‚
è¯¦è§[hf2mgæƒé‡è½¬æ¢](./pytorch/solutions/checkpoint_convert.md#21-huggingfaceæƒé‡è½¬æ¢åˆ°megatron-lmæ ¼å¼)

ä½¿ç”¨å®˜æ–¹æä¾›çš„è½¬æ¢è„šæœ¬ï¼Œè·å–å¯¹åº”åˆ‡åˆ†çš„mgæƒé‡ã€‚

```bash
cd MindSpeed-LLM

# è¯·å…ˆæ ¹æ®å¦‚ä¸‹æŒ‡å¯¼å®Œæˆè„šæœ¬ä¿®æ”¹é…ç½®
bash examples/mcore/qwen25/ckpt_convert_qwen25_hf2mcore.sh
```

å¦‚ä¸‹ä¸ºè°ƒæ•´åçš„hf2mcoreæƒé‡è½¬æ¢ç¤ºä¾‹è„šæœ¬

```bash
source /usr/local/Ascend/ascend-toolkit/set_env.sh

python convert_ckpt.py \
       --use-mcore-models \
       --model-type GPT \
       --load-model-type hf \
       --save-model-type mg \
       --target-tensor-parallel-size 1 \   # é€šè¿‡è¿™é‡Œå°†åˆ‡åˆ†è°ƒæ•´ä¸ºtp1pp4
       --target-pipeline-parallel-size 4 \ #
       --add-qkv-bias \
       --load-dir ./model_from_hf/qwen2.5-7b-hf/ \
       --save-dir ./model_weights/qwen2.5_mcore/ \
       --tokenizer-model ./model_from_hf/qwen2.5-7b-hf/tokenizer.json \
       --model-type-hf llama2 \
       --params-dtype bf16
```

å‚æ•°è§£æ

| å‚æ•°                                  | è¯´æ˜                                                         | å¿…å¡« |
|-------------------------------------|------------------------------------------------------------|---|
| `--model-type GPT`                  | æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºGPTç³»åˆ—                                               | âœ… |
| `--use-mcore-models`                | è½¬æ¢ä¸ºMegatron-Mcoreæ ¼å¼                        | âœ… |
| `--target-tensor-parallel-size 1`   | å¼ é‡å¹¶è¡Œåº¦è®¾ç½®ï¼ˆå»ºè®®é…ç½®1ï¼‰                                             | âœ… |
| `--target-pipeline-parallel-size 4` | æµæ°´çº¿å¹¶è¡Œåº¦è®¾ç½®ï¼ˆå»ºè®®ä¿æŒ4ï¼‰                                            | âœ… |
| `--tokenizer-model`                 | æŒ‡å®šåˆ†è¯å™¨è·¯å¾„                                                    | âœ… |
| `--load-model-type`                 | åŠ è½½æƒé‡çš„ç±»åˆ«ï¼ˆå¯ä»¥æ˜¯hfã€mgï¼‰                                          | âœ… |
| `--save-model-type`                 | å­˜å‚¨æƒé‡çš„ç±»åˆ«ï¼ˆå¯ä»¥æ˜¯hfã€mgï¼‰                                          | âœ… |
| `--load-dir`                 | æƒé‡æ–‡ä»¶åŠ è½½è·¯å¾„                                          | âœ… |
| `--save-dir`                 | æƒé‡æ–‡ä»¶ä¿å­˜è·¯å¾„                                          | âœ… |
| `--model-type-hf`                 | huggingfaceæ¨¡å‹ç±»åˆ«ï¼Œé»˜è®¤ä¸ºllama2                                  |   |
| `--params-dtype`                 | æŒ‡å®šæƒé‡è½¬æ¢åçš„æƒé‡ç²¾åº¦æ¨¡å¼ï¼Œé»˜è®¤ä¸ºfp16ï¼Œå¦‚æœæºæ–‡ä»¶æ ¼å¼ä¸ºbf16ï¼Œåˆ™éœ€è¦è®¾ç½®ä¸ºbf16 | âœ…  |

- æ³¨æ„ï¼šå¯¹è¯¥qwen2.5-7bæ¨¡å‹ï¼Œæ­¤å¤„æ¨èçš„åˆ‡åˆ†é…ç½®æ˜¯tp1pp4ï¼Œå¯¹åº”ä¸Šè¿°é…ç½®ã€‚

## 3.2 é¢„è®­ç»ƒæ•°æ®é›†å¤„ç†

é€šè¿‡å¯¹å„ç§æ ¼å¼çš„æ•°æ®åšæå‰é¢„å¤„ç†ï¼Œé¿å…åŸå§‹æ•°æ®çš„åå¤å¤„ç†åŠ è½½ï¼Œå°†æ‰€æœ‰çš„æ•°æ®éƒ½ç»Ÿä¸€å­˜å‚¨åˆ°ä¸º.binå’Œ.idxä¸¤ä¸ªæ–‡ä»¶ä¸­ï¼Œè¯¦è§[é¢„è®­ç»ƒæ•°æ®å¤„ç†](./pytorch/solutions/pretrain/pretrain_dataset.md)

å¸¸ç”¨çš„é¢„è®­ç»ƒæ•°æ®é›†åŒ…æ‹¬alpacaã€enwikiã€c4ç­‰ï¼Œé“¾æ¥ä¸­æä¾›äº†æ•°æ®é›†ä¸‹è½½åœ°å€ã€‚

### é¢„è®­ç»ƒæ•°æ®é›†ä¸‹è½½

å¦‚ä¸‹ä»¥alpacaæ•°æ®é›†ä¸ºä¾‹ï¼Œè¿›è¡Œé¢„è®­ç»ƒæ•°æ®é›†ç¤ºä¾‹ã€‚

```shell
# æ ¹æ®é“¾æ¥æä¾›åœ°å€ï¼Œé€šè¿‡wgetè·å–æ•°æ®é›†å…ƒæ•°æ®
mkdir dataset
cd dataset/
wget https://huggingface.co/datasets/tatsu-lab/alpaca/blob/main/data/train-00000-of-00001-a09b74b3ef9c3b56.parquet
cd ..

# ä½¿ç”¨ä»“åº“æä¾›çš„æ•°æ®å¤„ç†è„šæœ¬ï¼Œè·å–é¢„è®­ç»ƒæ•°æ®é›†ã€‚
# è¯·æ ¹æ®å¦‚ä¸‹æŒ‡å¯¼å®Œæˆè„šæœ¬ä¿®æ”¹é…ç½®
bash examples/mcore/qwen25/data_convert_qwen25_pretrain.sh
```
data_convert_qwen25_pretrain.shä¸­çš„é…ç½®éœ€åšå¦‚ä¸‹ä¿®æ”¹ï¼š
```shell
# è¯·æŒ‰ç…§æ‚¨çš„çœŸå®ç¯å¢ƒä¿®æ”¹ set_env.sh è·¯å¾„
source /usr/local/Ascend/ascend-toolkit/set_env.sh

python ./preprocess_data.py \
	--input ./dataset/train-00000-of-00001-a09b74b3ef9c3b56.parquet \
	--tokenizer-name-or-path ./model_from_hf/qwen2.5-7b-hf/ \         # æ³¨æ„æ­¤å¤„è·¯å¾„æ˜¯å¦ä¸€è‡´
	--output-prefix ./dataset/alpaca \                                # é¢„è®­ç»ƒæ•°æ®é›†ä¼šç”Ÿæˆalpaca_text_document.binå’Œ.idx
	--tokenizer-type PretrainedFromHF \
	--workers 4 \
	--log-interval 1000
```

å‚æ•°è§£æ

| å‚æ•°                       | è¯´æ˜                                                               | å¿…å¡« |
|---------------------------|------------------------------------------------------------------|--|
| `--input`                 | æ”¯æŒè¾“å…¥æ•°æ®é›†ç›®å½•æˆ–æ–‡ä»¶ï¼Œç›®å½•åˆ™å¤„ç†å…¨éƒ¨æ–‡ä»¶, æ”¯æŒ.parquetã€.csvã€.jsonã€.jsonlã€.txtã€.arrowæ ¼å¼ï¼ŒåŒä¸€ç›®å½•è¦æ±‚æ•°æ®æ ¼å¼ä¿æŒä¸€è‡´ | âœ… |
| `--tokenizer-type` | è¯´æ˜ä½¿ç”¨tokenizerç±»åˆ«ï¼Œå‚æ•°å€¼ä¸ºPretrainedFromHFæ—¶ï¼Œè¯è¡¨è·¯å¾„å¡«å†™æ¨¡å‹ç›®å½•å³å¯               | âœ… |
| `--tokenizer-name-or-path`| é…åˆtokenizer-typeï¼Œç›®æ ‡æ¨¡å‹çš„tokenizeråŸæ•°æ®æ–‡ä»¶å¤¹ï¼Œç”¨äºæ•°æ®é›†çš„è½¬æ¢                   |  |
| `--tokenizer-model`       | é…åˆæŒ‡å®šåˆ†è¯å™¨æ¨¡å‹çš„è·¯å¾„ï¼Œè·¯å¾„å…·ä½“åˆ°tokenizer.modelæ–‡ä»¶                              |  |
| `--output-prefix`  | è½¬æ¢åè¾“å‡ºçš„æ•°æ®é›†æ–‡ä»¶çš„æ–‡ä»¶åå‰ç¼€                                                | âœ… |
| `--workers`               | å¤šè¿›ç¨‹æ•°æ®é›†å¤„ç†                                                         | âœ… |

## 3.3 é¢„è®­ç»ƒä»»åŠ¡å¯åŠ¨

å®Œæˆäº†æ•°æ®é›†å¤„ç†å’Œæƒé‡è½¬æ¢ä¹‹åï¼Œå¯ä»¥å¼€å§‹æ‹‰èµ·é¢„è®­ç»ƒä»»åŠ¡ã€‚

### å¯åŠ¨å•æœºé¢„è®­ç»ƒ

#### é…ç½®é¢„è®­ç»ƒå‚æ•°

 ```shell
# æ‰“å¼€ç¤ºä¾‹è„šæœ¬
vi examples/mcore/qwen25/pretrain_qwen25_7b_32k_ptd.sh

# å•æœºé…ç½®å¦‚ä¸‹
NPUS_PER_NODE=8           # ä½¿ç”¨å•èŠ‚ç‚¹çš„8å¡NPU
MASTER_ADDR=locahost      # ä»¥æœ¬èŠ‚ç‚¹ipåœ°å€ä¸ºmaster_ip
MASTER_PORT=6000          # æœ¬èŠ‚ç‚¹ç«¯å£å·ä¸º6000
NNODES=1                  # å•æœºï¼Œå³ä¸€å°èŠ‚ç‚¹ï¼Œå¤šæœºå³å¤šèŠ‚ç‚¹
NODE_RANK=0               # å•æœºRANKä¸º0ï¼Œå¤šæœºä¸º(0,NNODES-1)ï¼Œä¸åŒèŠ‚ç‚¹ä¸å¯é‡å¤
WORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))

# æ ¹æ®å®é™…æƒ…å†µé…ç½®æƒé‡ä¿å­˜ã€æƒé‡åŠ è½½ã€è¯è¡¨ã€æ•°æ®é›†è·¯å¾„
CKPT_LOAD_DIR="./model_weights/qwen2.5_mcore/"  # æƒé‡åŠ è½½è·¯å¾„ï¼Œå¡«å…¥æƒé‡è½¬æ¢æ—¶ä¿å­˜çš„æƒé‡è·¯å¾„
CKPT_SAVE_DIR="./ckpt/qwen25-7b"                # è®­ç»ƒå®Œæˆåçš„æƒé‡ä¿å­˜è·¯å¾„
DATA_PATH="./dataset/alpaca_text_document"      # æ•°æ®é›†è·¯å¾„ï¼Œå¡«å…¥æ•°æ®é¢„å¤„ç†æ—¶ä¿å­˜çš„æ•°æ®è·¯å¾„ï¼Œæ³¨æ„éœ€è¦æ·»åŠ åç¼€
TOKENIZER_PATH="./model_from_hf/qwen2.5-7b-hf/" # è¯è¡¨è·¯å¾„ï¼Œå¡«å…¥ä¸‹è½½çš„å¼€æºæƒé‡è¯è¡¨è·¯å¾„

TP=1                # æƒé‡è½¬æ¢è®¾ç½®--target-tensor-parallel-size 1ï¼Œä¿®æ”¹ä¸º1
PP=4                # æƒé‡è½¬æ¢è®¾ç½®--target-pipeline-parallel-size 4ï¼Œä¿®æ”¹ä¸º4ï¼Œä¸æƒé‡è½¬æ¢æ—¶ä¸€è‡´
SEQ_LEN=4096        # ä¿®æ”¹seq_lengthä¸º4096 
MBS=1               # è®¾ç½®micro-batch-sizeä¸º1
GBS=64              # è®¾ç½®global-batch-sizeä¸º64

# å®Œæˆå¦‚ä¸Šä¿®æ”¹åä¿å­˜å…³é—­è„šæœ¬
 ```

```shell
# åˆå§‹åŒ–ç¯å¢ƒå˜é‡
source /usr/local/Ascend/ascend-toolkit/set_env.sh
source /usr/local/Ascend/nnal/atb/set_env.sh

# å¯åŠ¨é¢„è®­ç»ƒè„šæœ¬
bash examples/mcore/qwen25/pretrain_qwen25_7b_32k_ptd.sh
```
![img_2.png](../sources/images/quick_start/running_log.png)

è„šæœ¬ä¸­ç‰¹æ€§åŒ…å«è®­ç»ƒå‚æ•°ä¹ŸåŒ…å«ä¼˜åŒ–ç‰¹æ€§ï¼Œå¦‚ä¸‹éƒ¨åˆ†å‚æ•°è§£é‡Š

| å‚æ•°å                                     | è¯´æ˜                              |
|-----------------------------------------|---------------------------------| 
| `--use-mcore-models`                    | ä½¿ç”¨mcoreåˆ†æ”¯è¿è¡Œæ¨¡å‹     |          
| `--disable-bias-linear`                 | å»æ‰linearçš„åç§»å€¼ï¼Œä¸qwenåŸæ¨¡å‹ä¸€è‡´         | 
| `--add-qkv-bias`                        | å¢åŠ Qã€Kã€Vçš„åç§»å€¼ï¼Œæ˜¯æƒé‡çš„ç»„æˆéƒ¨åˆ†            | 
| `--group-query-attention`               | å¼€å¯GQAæ³¨æ„åŠ›å¤„ç†æœºåˆ¶                    |
| `--num-query-groups 4`                  | é…åˆGQAä½¿ç”¨ï¼Œè®¾ç½®groupsä¸º4              |
| `--position-embedding-type rope`        | ä½ç½®ç¼–ç é‡‡ç”¨ropeæ–¹æ¡ˆ                    |
| `--untie-embeddings-and-output-weights` | æ ¹æ®åŸæ¨¡å‹è¦æ±‚å°†outputå±‚å’Œembeddingå±‚çš„æƒé‡è§£è€¦ |
| `--bf16`                                | æ˜‡è…¾èŠ¯ç‰‡å¯¹BF16ç²¾åº¦æ”¯æŒè‰¯å¥½ï¼Œå¯æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦       |

### å¯åŠ¨å¤šæœºé¢„è®­ç»ƒä»»åŠ¡

å¦‚æœéœ€è¦å¯åŠ¨å¤šæœºé¢„è®­ç»ƒä»»åŠ¡ï¼Œé‚£ä¹ˆåœ¨å•æœºé¢„è®­ç»ƒè„šæœ¬çš„åŸºç¡€ä¸Šï¼Œåšå¦‚ä¸‹ä¿®æ”¹ï¼Œ

#### é…ç½®é¢„è®­ç»ƒå‚æ•°

 ```shell
# vi examples/mcore/qwen25/pretrain_qwen25_7b_32k_ptd.sh æ‰“å¼€ç¤ºä¾‹è„šæœ¬

# å•æœºé…ç½®å¦‚ä¸‹
NPUS_PER_NODE=8           # åŒå•æœº
MASTER_ADDR=${master_ip}  # å‚ä¸å¤šæœºè®­ç»ƒçš„èŠ‚ç‚¹éƒ½é…ç½®ä¸ºmaster_ip
MASTER_PORT=6000          # æœ¬èŠ‚ç‚¹ç«¯å£å·ä¸º6000
NNODES=1                  # æ ¹æ®å‚ä¸èŠ‚ç‚¹æ•°é‡é…ç½®
NODE_RANK=0               # å¤šæœºä¸º(0,NNODES-1)ï¼Œä¸åŒèŠ‚ç‚¹ä¸å¯é‡å¤ï¼Œmaster_node rankä¸º0ï¼Œå…¶ipä¸ºmaster_ip
WORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))

# å‚ä¸èŠ‚ç‚¹éƒ½è¦æœ‰å¦‚ä¸‹æ•°æ®
CKPT_LOAD_DIR="./model_weights/qwen2.5_mcore/"  
CKPT_SAVE_DIR="./ckpt/qwen25-7b"                
DATA_PATH="./dataset/alpaca_text_document"      
TOKENIZER_PATH="./model_from_hf/qwen2.5-7b-hf/" 
 ```

**æ³¨æ„**ï¼š

- å¤šæœºè®­ç»ƒéœ€åœ¨å¤šä¸ªç»ˆç«¯åŒæ—¶å¯åŠ¨é¢„è®­ç»ƒè„šæœ¬(æ¯ä¸ªç»ˆç«¯çš„é¢„è®­ç»ƒè„šæœ¬åªæœ‰NODE_RANKå‚æ•°ä¸åŒï¼Œå…¶ä»–å‚æ•°å‡ç›¸åŒ)
- å¦‚æœä½¿ç”¨å¤šæœºè®­ç»ƒï¼Œä¸”æ²¡æœ‰è®¾ç½®æ•°æ®å…±äº«ï¼Œéœ€è¦åœ¨è®­ç»ƒå¯åŠ¨è„šæœ¬ä¸­å¢åŠ `--no-shared-storage`å‚æ•°ï¼Œè®¾ç½®æ­¤å‚æ•°ä¹‹åå°†ä¼šæ ¹æ®å¸ƒå¼å‚æ•°åˆ¤æ–­éä¸»èŠ‚ç‚¹æ˜¯å¦éœ€è¦loadæ•°æ®ï¼Œå¹¶æ£€æŸ¥ç›¸åº”ç¼“å­˜å’Œç”Ÿæˆæ•°æ®

# 4 åŸºäºmindsporeåç«¯çš„é¢„è®­ç»ƒ

åœ¨è¿™ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬å°†åŸºäºä¸‹è½½çš„HuggingFace(hf)åŸæ•°æ®ï¼Œå®Œæˆæƒé‡è½¬æ¢ã€æ•°æ®é›†é¢„å¤„ç†ï¼Œå¯åŠ¨æ¨¡å‹é¢„è®­ç»ƒï¼ŒåŒ…å«æ­¥éª¤å¦‚ä¸‹ï¼š

- hfæƒé‡è½¬æ¢æˆmegatronæƒé‡ï¼›
- é¢„è®­ç»ƒæ•°æ®é›†å¤„ç†ï¼›
- é¢„è®­ç»ƒä»»åŠ¡å¯åŠ¨ã€‚

## 4.1 æƒé‡è½¬æ¢

æ˜‡è…¾MindSpeed-LLMè¦æ±‚æ¨¡å‹æƒé‡é‡‡ç”¨Megatron-LMæ ¼å¼ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å°†åŸå§‹HuggingFaceæƒé‡æ ¼å¼è½¬æ¢ä¸ºMegatron-Mcoreæ ¼å¼ã€‚
è¯¦è§[hf2mgæƒé‡è½¬æ¢](./pytorch/solutions/checkpoint_convert.md#21-huggingfaceæƒé‡è½¬æ¢åˆ°megatron-lmæ ¼å¼)

ä½¿ç”¨å®˜æ–¹æä¾›çš„è½¬æ¢è„šæœ¬ï¼Œè·å–å¯¹åº”åˆ‡åˆ†çš„mgæƒé‡ã€‚

```bash
cd MindSpeed-LLM

# è¯·å…ˆæ ¹æ®å¦‚ä¸‹æŒ‡å¯¼å®Œæˆè„šæœ¬ä¿®æ”¹é…ç½®
bash examples/mindspore/qwen25/ckpt_convert_qwen25_hf2mcore.sh
```

å¦‚ä¸‹ä¸ºè°ƒæ•´åçš„hf2mcoreæƒé‡è½¬æ¢ç¤ºä¾‹è„šæœ¬

```bash
source /usr/local/Ascend/ascend-toolkit/set_env.sh

python convert_ckpt.py \
       --use-mcore-models \
       --model-type GPT \
       --load-model-type hf \
       --save-model-type mg \
       --target-tensor-parallel-size 1 \   # é€šè¿‡è¿™é‡Œå°†åˆ‡åˆ†è°ƒæ•´ä¸ºtp1pp4
       --target-pipeline-parallel-size 4 \ #
       --add-qkv-bias \
       --load-dir ./model_from_hf/qwen2.5-7b-hf/ \
       --save-dir ./model_weights/qwen2.5_mcore/ \
       --tokenizer-model ./model_from_hf/qwen2.5-7b-hf/tokenizer.json \
       --model-type-hf llama2 \
       --params-dtype bf16
```

å‚æ•°è§£æ

| å‚æ•°                                  | è¯´æ˜                                                         | å¿…å¡« |
|-------------------------------------|------------------------------------------------------------|---|
| `--model-type GPT`                  | æŒ‡å®šæ¨¡å‹ç±»å‹ä¸ºGPTç³»åˆ—                                               | âœ… |
| `--use-mcore-models`                | è½¬æ¢ä¸ºMegatron-Mcoreæ ¼å¼                        | âœ… |
| `--target-tensor-parallel-size 1`   | å¼ é‡å¹¶è¡Œåº¦è®¾ç½®ï¼ˆå»ºè®®é…ç½®1ï¼‰                                             | âœ… |
| `--target-pipeline-parallel-size 4` | æµæ°´çº¿å¹¶è¡Œåº¦è®¾ç½®ï¼ˆå»ºè®®ä¿æŒ4ï¼‰                                            | âœ… |
| `--tokenizer-model`                 | æŒ‡å®šåˆ†è¯å™¨è·¯å¾„                                                    | âœ… |
| `--load-model-type`                 | åŠ è½½æƒé‡çš„ç±»åˆ«ï¼ˆå¯ä»¥æ˜¯hfã€mgï¼‰                                          | âœ… |
| `--save-model-type`                 | å­˜å‚¨æƒé‡çš„ç±»åˆ«ï¼ˆå¯ä»¥æ˜¯hfã€mgï¼‰                                          | âœ… |
| `--load-dir`                 | æƒé‡æ–‡ä»¶åŠ è½½è·¯å¾„                                          | âœ… |
| `--save-dir`                 | æƒé‡æ–‡ä»¶ä¿å­˜è·¯å¾„                                          | âœ… |
| `--model-type-hf`                 | huggingfaceæ¨¡å‹ç±»åˆ«ï¼Œé»˜è®¤ä¸ºllama2                                  |   |
| `--params-dtype`                 | æŒ‡å®šæƒé‡è½¬æ¢åçš„æƒé‡ç²¾åº¦æ¨¡å¼ï¼Œé»˜è®¤ä¸ºfp16ï¼Œå¦‚æœæºæ–‡ä»¶æ ¼å¼ä¸ºbf16ï¼Œåˆ™éœ€è¦è®¾ç½®ä¸ºbf16 | âœ…  |

**æ³¨æ„**
- å¯¹è¯¥qwen2.5-7bæ¨¡å‹ï¼Œæ­¤å¤„æ¨èçš„åˆ‡åˆ†é…ç½®æ˜¯tp1pp4ï¼Œå¯¹åº”ä¸Šè¿°é…ç½®ã€‚
- å½“å‰å°šä¸æ”¯æŒQLoRAæƒé‡é‡åŒ–è½¬æ¢ï¼Œã€--qlora-nf4ã€‘å‚æ•°ä»…å¯ç½®ä¸ºFalseã€‚
- MindSpore åç«¯é»˜è®¤åœ¨Deviceä¾§è¿›è¡Œæƒé‡è½¬æ¢ï¼Œåœ¨æ¨¡å‹è¾ƒå¤§æ—¶å­˜åœ¨OOMé£é™©ï¼Œå› æ­¤å»ºè®®ç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹`convert_ckpt.py`ï¼Œåœ¨åŒ…å¯¼å…¥æ—¶åŠ å…¥å¦‚ä¸‹ä»£ç è®¾ç½®CPUä¾§æ‰§è¡Œæƒé‡è½¬æ¢ï¼š

```python
import mindspore as ms
ms.set_context(device_target="CPU", pynative_synchronize=True)
import torch
torch.configs.set_pyboost(False)
```

- MindSpore åç«¯è½¬æ¢å‡ºçš„æ¨¡å‹æƒé‡æ— æ³•ç›´æ¥ç”¨äº Torchåç«¯è®­ç»ƒæˆ–æ¨ç†ã€‚


## 4.2 é¢„è®­ç»ƒæ•°æ®é›†å¤„ç†

é€šè¿‡å¯¹å„ç§æ ¼å¼çš„æ•°æ®åšæå‰é¢„å¤„ç†ï¼Œé¿å…åŸå§‹æ•°æ®çš„åå¤å¤„ç†åŠ è½½ï¼Œå°†æ‰€æœ‰çš„æ•°æ®éƒ½ç»Ÿä¸€å­˜å‚¨åˆ°ä¸º.binå’Œ.idxä¸¤ä¸ªæ–‡ä»¶ä¸­ï¼Œè¯¦è§[é¢„è®­ç»ƒæ•°æ®å¤„ç†](./pytorch/solutions/pretrain/pretrain_dataset.md)ã€‚

å¸¸ç”¨çš„é¢„è®­ç»ƒæ•°æ®é›†åŒ…æ‹¬alpacaã€enwikiã€c4ç­‰ï¼Œé“¾æ¥ä¸­æä¾›äº†æ•°æ®é›†ä¸‹è½½åœ°å€ã€‚

### é¢„è®­ç»ƒæ•°æ®é›†ä¸‹è½½

å¦‚ä¸‹ä»¥alpacaæ•°æ®é›†ä¸ºä¾‹ï¼Œè¿›è¡Œé¢„è®­ç»ƒæ•°æ®é›†ç¤ºä¾‹ã€‚

```shell
# æ ¹æ®é“¾æ¥æä¾›åœ°å€ï¼Œé€šè¿‡wgetè·å–æ•°æ®é›†å…ƒæ•°æ®
mkdir dataset
cd dataset/
wget https://huggingface.co/datasets/tatsu-lab/alpaca/blob/main/data/train-00000-of-00001-a09b74b3ef9c3b56.parquet
cd ..

# ä½¿ç”¨ä»“åº“æä¾›çš„æ•°æ®å¤„ç†è„šæœ¬ï¼Œè·å–é¢„è®­ç»ƒæ•°æ®é›†ã€‚
# è¯·æ ¹æ®å¦‚ä¸‹æŒ‡å¯¼å®Œæˆè„šæœ¬ä¿®æ”¹é…ç½®
bash examples/mindspore/qwen25/data_convert_qwen25_pretrain.sh
```
data_convert_qwen25_pretrain.shä¸­çš„é…ç½®éœ€åšå¦‚ä¸‹ä¿®æ”¹ï¼š
```shell
# è¯·æŒ‰ç…§æ‚¨çš„çœŸå®ç¯å¢ƒä¿®æ”¹ set_env.sh è·¯å¾„
source /usr/local/Ascend/ascend-toolkit/set_env.sh

python ./preprocess_data.py \
    --input ./dataset/train-00000-of-00001-a09b74b3ef9c3b56.parquet \
    --tokenizer-name-or-path ./model_from_hf/qwen2.5-7b-hf/ \         # æ³¨æ„æ­¤å¤„è·¯å¾„æ˜¯å¦ä¸€è‡´
    --output-prefix ./dataset/alpaca \                                # é¢„è®­ç»ƒæ•°æ®é›†ä¼šç”Ÿæˆalpaca_text_document.binå’Œ.idx
    --tokenizer-type PretrainedFromHF \
    --workers 4 \
    --log-interval 1000
```

å‚æ•°è§£æ

| å‚æ•°                       | è¯´æ˜                                                               | å¿…å¡« |
|---------------------------|------------------------------------------------------------------|--|
| `--input`                 | æ”¯æŒè¾“å…¥æ•°æ®é›†ç›®å½•æˆ–æ–‡ä»¶ï¼Œç›®å½•åˆ™å¤„ç†å…¨éƒ¨æ–‡ä»¶, æ”¯æŒ.parquetã€.csvã€.jsonã€.jsonlã€.txtã€.arrowæ ¼å¼ï¼ŒåŒä¸€ç›®å½•è¦æ±‚æ•°æ®æ ¼å¼ä¿æŒä¸€è‡´ | âœ… |
| `--tokenizer-type` | è¯´æ˜ä½¿ç”¨tokenizerç±»åˆ«ï¼Œå‚æ•°å€¼ä¸ºPretrainedFromHFæ—¶ï¼Œè¯è¡¨è·¯å¾„å¡«å†™æ¨¡å‹ç›®å½•å³å¯               | âœ… |
| `--tokenizer-name-or-path`| é…åˆtokenizer-typeï¼Œç›®æ ‡æ¨¡å‹çš„tokenizeråŸæ•°æ®æ–‡ä»¶å¤¹ï¼Œç”¨äºæ•°æ®é›†çš„è½¬æ¢                   |  |
| `--tokenizer-model`       | é…åˆæŒ‡å®šåˆ†è¯å™¨æ¨¡å‹çš„è·¯å¾„ï¼Œè·¯å¾„å…·ä½“åˆ°tokenizer.modelæ–‡ä»¶                              |  |
| `--output-prefix`  | è½¬æ¢åè¾“å‡ºçš„æ•°æ®é›†æ–‡ä»¶çš„æ–‡ä»¶åå‰ç¼€                                                | âœ… |
| `--workers`               | å¤šè¿›ç¨‹æ•°æ®é›†å¤„ç†                                                         | âœ… |

## 4.3 é¢„è®­ç»ƒä»»åŠ¡å¯åŠ¨

å®Œæˆäº†æ•°æ®é›†å¤„ç†å’Œæƒé‡è½¬æ¢ä¹‹åï¼Œå¯ä»¥å¼€å§‹æ‹‰èµ·é¢„è®­ç»ƒä»»åŠ¡ã€‚

### å¯åŠ¨å•æœºé¢„è®­ç»ƒ

#### é…ç½®é¢„è®­ç»ƒå‚æ•°

 ```shell
# æ‰“å¼€ç¤ºä¾‹è„šæœ¬
vi examples/mindspore/qwen25/pretrain_qwen25_7b_32k_ms.sh

# å•æœºé…ç½®å¦‚ä¸‹
NPUS_PER_NODE=8           # ä½¿ç”¨å•èŠ‚ç‚¹çš„8å¡NPU
MASTER_ADDR=locahost      # ä»¥æœ¬èŠ‚ç‚¹ipåœ°å€ä¸ºmaster_ip
MASTER_PORT=6000          # æœ¬èŠ‚ç‚¹ç«¯å£å·ä¸º6000
NNODES=1                  # å•æœºï¼Œå³ä¸€å°èŠ‚ç‚¹ï¼Œå¤šæœºå³å¤šèŠ‚ç‚¹
NODE_RANK=0               # å•æœºRANKä¸º0ï¼Œå¤šæœºä¸º(0,NNODES-1)ï¼Œä¸åŒèŠ‚ç‚¹ä¸å¯é‡å¤
WORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))

# æ ¹æ®å®é™…æƒ…å†µé…ç½®æƒé‡ä¿å­˜ã€æƒé‡åŠ è½½ã€è¯è¡¨ã€æ•°æ®é›†è·¯å¾„
CKPT_LOAD_DIR="./model_weights/qwen2.5_mcore/"  # æƒé‡åŠ è½½è·¯å¾„ï¼Œå¡«å…¥æƒé‡è½¬æ¢æ—¶ä¿å­˜çš„æƒé‡è·¯å¾„
CKPT_SAVE_DIR="./ckpt/qwen25-7b"                # è®­ç»ƒå®Œæˆåçš„æƒé‡ä¿å­˜è·¯å¾„
DATA_PATH="./dataset/alpaca_text_document"      # æ•°æ®é›†è·¯å¾„ï¼Œå¡«å…¥æ•°æ®é¢„å¤„ç†æ—¶ä¿å­˜çš„æ•°æ®è·¯å¾„ï¼Œæ³¨æ„éœ€è¦æ·»åŠ åç¼€
TOKENIZER_PATH="./model_from_hf/qwen2.5-7b-hf/" # è¯è¡¨è·¯å¾„ï¼Œå¡«å…¥ä¸‹è½½çš„å¼€æºæƒé‡è¯è¡¨è·¯å¾„

TP=1                # æƒé‡è½¬æ¢è®¾ç½®--target-tensor-parallel-size 1ï¼Œä¿®æ”¹ä¸º1
PP=4                # æƒé‡è½¬æ¢è®¾ç½®--target-pipeline-parallel-size 4ï¼Œä¿®æ”¹ä¸º4ï¼Œä¸æƒé‡è½¬æ¢æ—¶ä¸€è‡´
SEQ_LEN=4096        # ä¿®æ”¹seq_lengthä¸º4096 
MBS=1               # è®¾ç½®micro-batch-sizeä¸º1
GBS=64              # è®¾ç½®global-batch-sizeä¸º64

# å®Œæˆå¦‚ä¸Šä¿®æ”¹åä¿å­˜å…³é—­è„šæœ¬
 ```

```shell
# åˆå§‹åŒ–ç¯å¢ƒå˜é‡
source /usr/local/Ascend/ascend-toolkit/set_env.sh
source /usr/local/Ascend/nnal/atb/set_env.sh cxx_abi=0

# å¯åŠ¨é¢„è®­ç»ƒè„šæœ¬
bash examples/mindspore/qwen25/pretrain_qwen25_7b_32k_ms.sh
```
![img_2.png](../sources/images/quick_start/running_log.png)

è„šæœ¬ä¸­ç‰¹æ€§åŒ…å«è®­ç»ƒå‚æ•°ä¹ŸåŒ…å«ä¼˜åŒ–ç‰¹æ€§ï¼Œå¦‚ä¸‹éƒ¨åˆ†å‚æ•°è§£é‡Š

| å‚æ•°å                                     | è¯´æ˜                              |
|-----------------------------------------|---------------------------------| 
| `--use-mcore-models`                    | ä½¿ç”¨mcoreåˆ†æ”¯è¿è¡Œæ¨¡å‹     |          
| `--disable-bias-linear`                 | å»æ‰linearçš„åç§»å€¼ï¼Œä¸qwenåŸæ¨¡å‹ä¸€è‡´         | 
| `--add-qkv-bias`                        | å¢åŠ Qã€Kã€Vçš„åç§»å€¼ï¼Œæ˜¯æƒé‡çš„ç»„æˆéƒ¨åˆ†            | 
| `--group-query-attention`               | å¼€å¯GQAæ³¨æ„åŠ›å¤„ç†æœºåˆ¶                    |
| `--num-query-groups 4`                  | é…åˆGQAä½¿ç”¨ï¼Œè®¾ç½®groupsä¸º4              |
| `--position-embedding-type rope`        | ä½ç½®ç¼–ç é‡‡ç”¨ropeæ–¹æ¡ˆ                    |
| `--untie-embeddings-and-output-weights` | æ ¹æ®åŸæ¨¡å‹è¦æ±‚å°†outputå±‚å’Œembeddingå±‚çš„æƒé‡è§£è€¦ |
| `--bf16`                                | æ˜‡è…¾èŠ¯ç‰‡å¯¹BF16ç²¾åº¦æ”¯æŒè‰¯å¥½ï¼Œå¯æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦       |

### å¯åŠ¨å¤šæœºé¢„è®­ç»ƒä»»åŠ¡

å¦‚æœéœ€è¦å¯åŠ¨å¤šæœºé¢„è®­ç»ƒä»»åŠ¡ï¼Œé‚£ä¹ˆåœ¨å•æœºé¢„è®­ç»ƒè„šæœ¬çš„åŸºç¡€ä¸Šï¼Œåšå¦‚ä¸‹ä¿®æ”¹ï¼Œ

#### é…ç½®é¢„è®­ç»ƒå‚æ•°

 ```shell
# vi examples/mindspore/qwen25/pretrain_qwen25_7b_32k_ms.sh æ‰“å¼€ç¤ºä¾‹è„šæœ¬

# å•æœºé…ç½®å¦‚ä¸‹
NPUS_PER_NODE=8           # åŒå•æœº
MASTER_ADDR=${master_ip}  # å‚ä¸å¤šæœºè®­ç»ƒçš„èŠ‚ç‚¹éƒ½é…ç½®ä¸ºmaster_ip
MASTER_PORT=6000          # æœ¬èŠ‚ç‚¹ç«¯å£å·ä¸º6000
NNODES=1                  # æ ¹æ®å‚ä¸èŠ‚ç‚¹æ•°é‡é…ç½®
NODE_RANK=0               # å¤šæœºä¸º(0,NNODES-1)ï¼Œä¸åŒèŠ‚ç‚¹ä¸å¯é‡å¤ï¼Œmaster_node rankä¸º0ï¼Œå…¶ipä¸ºmaster_ip
WORLD_SIZE=$(($GPUS_PER_NODE * $NNODES))

# å‚ä¸èŠ‚ç‚¹éƒ½è¦æœ‰å¦‚ä¸‹æ•°æ®
CKPT_LOAD_DIR="./model_weights/qwen2.5_mcore/"  
CKPT_SAVE_DIR="./ckpt/qwen25-7b"                
DATA_PATH="./dataset/alpaca_text_document"      
TOKENIZER_PATH="./model_from_hf/qwen2.5-7b-hf/" 
 ```

**æ³¨æ„**ï¼š

- å¤šæœºè®­ç»ƒéœ€åœ¨å¤šä¸ªç»ˆç«¯åŒæ—¶å¯åŠ¨é¢„è®­ç»ƒè„šæœ¬(æ¯ä¸ªç»ˆç«¯çš„é¢„è®­ç»ƒè„šæœ¬åªæœ‰NODE_RANKå‚æ•°ä¸åŒï¼Œå…¶ä»–å‚æ•°å‡ç›¸åŒ)
- å¦‚æœä½¿ç”¨å¤šæœºè®­ç»ƒï¼Œä¸”æ²¡æœ‰è®¾ç½®æ•°æ®å…±äº«ï¼Œéœ€è¦åœ¨è®­ç»ƒå¯åŠ¨è„šæœ¬ä¸­å¢åŠ `--no-shared-storage`å‚æ•°ï¼Œè®¾ç½®æ­¤å‚æ•°ä¹‹åå°†ä¼šæ ¹æ®å¸ƒå¼å‚æ•°åˆ¤æ–­éä¸»èŠ‚ç‚¹æ˜¯å¦éœ€è¦loadæ•°æ®ï¼Œå¹¶æ£€æŸ¥ç›¸åº”ç¼“å­˜å’Œç”Ÿæˆæ•°æ®


# é™„å½•
## å¸¸è§é—®é¢˜
- **é—®é¢˜1ï¼šè®­ç»ƒæ—¥å¿—æ˜¾ç¤º"Checkpoint path not found"ï¼Ÿ**  
  â†’ æ£€æŸ¥`CKPT_LOAD_DIR`æ˜¯å¦æŒ‡å‘æ­£ç¡®çš„æƒé‡è½¬æ¢åè·¯å¾„ï¼Œç¡®è®¤æ–‡ä»¶å¤¹å†…åŒ…å«`.ckpt`æˆ–`.bin`æ–‡ä»¶ã€‚

![img_1.png](../sources/images/quick_start/img_1.png)

**é—®é¢˜2ï¼šæ˜¾ç¤ºæ•°æ®é›†åŠ è½½out of rangeï¼Ÿ**  
  â†’ å¾®è°ƒè„šæœ¬ï¼Œæ²¡æœ‰è¯»å–åˆ°æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥DATA_PATHæ˜¯å¦ç¬¦åˆä¸Šé¢ç¤ºä¾‹çš„è§„èŒƒã€‚

![img_3.png](../sources/images/quick_start/img_3.png)
 
- **é—®é¢˜3ï¼šè®­ç»ƒè„šæœ¬æ‹‰èµ·å¤±è´¥ï¼Ÿ**  
  â†’ æ£€æŸ¥æœ‰æ— sourceï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¿›ç¨‹æ®‹ç•™ï¼Œæœªæ¸…ç†å¹²å‡€ã€‚

- **é—®é¢˜4ï¼šæ²¡æœ‰ç”Ÿæˆè¿è¡Œæ—¥å¿—æ–‡ä»¶ï¼Ÿ**  
  â†’ éœ€è¦è‡ªè¡Œåˆ›å»ºlogsæ–‡ä»¶å¤¹ã€‚

![img_2.png](../sources/images/quick_start/img_2.png)

## åŠ å…¥æ˜‡è…¾å¼€å‘è€…ç”Ÿæ€

- ğŸŒÂ **ç¤¾åŒºèµ„æº**ï¼šè®¿é—®[æ˜‡è…¾å¼€æºç¤¾åŒº](https://gitee.com/ascend)è·å–æœ€æ–°æ¨¡å‹æ”¯æŒ
- ğŸ“ˆÂ **æ€§èƒ½ä¼˜åŒ–**ï¼šå‚è€ƒ[MindSpeed Profiling](pytorch/features/profiling.md)åˆ†æç“¶é¢ˆ
- ğŸ’¡Â **å®šåˆ¶éœ€æ±‚**ï¼šé€šè¿‡`model_cfg.json`æ‰©å±•è‡ªå®šä¹‰æ¨¡å‹

---

é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å·²æŒæ¡æ˜‡è…¾ç”Ÿæ€çš„åŸºç¡€æŠ€èƒ½ï¼Œèƒ½å¤Ÿæ­£å¸¸ä½¿ç”¨ä»“åº“çš„æ¨¡å‹é¢„è®­ç»ƒåŠŸèƒ½ã€‚ä¸‹ä¸€æ­¥ï¼Œä¸å¦¨å°è¯•æ›´æ·±å…¥ç†è§£è„šæœ¬ç‰¹æ€§å’Œä»“åº“ã€‚
- å°è¯•è¿›é˜¶èƒ½åŠ›ï¼Œè¯·å‚è€ƒç¿»é˜…[æ¨¡å‹è¿ç§»æŒ‡å—](https://gitee.com/ascend/MindSpeed-LLM/wikis/%E6%A8%A1%E5%9E%8B%E8%BF%81%E7%A7%BB)
- è¿›è¡Œæ¨¡å‹å¾®è°ƒã€æ¨¡å‹æ€§èƒ½ä¼˜åŒ–ï¼Œæ¨¡å‹åˆ‡åˆ†è°ƒæ•´ï¼Œæˆ–æ¢ç´¢[MOEæ··åˆä¸“å®¶æ¨¡å‹](https://gitee.com/ascend/MindSpeed-LLM/blob/master/README.md)ç­‰å‰æ²¿åº”ç”¨ï¼
